# README
# 🖥디스플레이 센서의 불량품 요인 분석

## Repository 구조
```
Factory-Anomaly-Analysis
├── 📁data 								# 오른쪽 컬럼, vif계수로 인한 피처제거된 데이터
|	├── 
|	├── 
├── 📁python                     
├── 📃1_결측치처리와_상관계수저장.ipynb
├── 📃2_PCA와 RandomForest(VIF).ipynb
└── 📃3_PCA와 RandomForest(noVIF).ipynb
```



## ✏프로젝트 과정 기록

[https://2sehi.github.io/categories/#k-digital-project](https://2sehi.github.io/categories/#k-digital-project)



### 목차

- [1.프로젝트 개요](#1프로젝트-개요)
- [2.데이터 탐색](#2데이터-탐색)
- [3.데이터 변환](#3데이터-변환)
- [4.모델링](#4모델링)
- [5.결론](#5결론)



## 1.프로젝트 개요
---

- [1) 프로젝트 목적](#1-프로젝트-목적)
- [2) 프로젝트 배경](#2-프로젝트-배경)
- [3) 평가지표](#3-평가지표)
- [4)-프로젝트 기간](#4-프로젝트-기간)
- [5) 프로젝트 분석 환경 도구](#5-프로젝트-분석-환경-도구)


### 1) 프로젝트 목적





> 생산공정 중 양품/불량품에 큰 영향을 미치는 저수율 요인 5개를 찾아내는 것을 목표로 함





- 웨이퍼 식각 후 테스트 단계에서 센서 측정값의 1시간 평균 데이터를 분석하여 **저수율 요인을 찾고자 함** 
  - 웨이퍼 식각 : 반도체 공정 중 하나로 TFT(박막트랜지스터)의 회로 패턴을 만들기 위해 웨이퍼의 필요한 부분만 남기고 불필요한 부분은 깎아내는 공정
- 테스트 과정에서 웨이퍼 상태의 반도체 칩의 불량여부를 선별 가능함 
- 저수율 요인을 찾아 설계상의 문제점이나 제조상의 문제점을 발견해 수정 가능함



### 2) 프로젝트 배경

- 저수율 웨이퍼 발생하는 원인은  반도체 공정의 각 프로세서에서 레시피(온도,압력,가공 시간 등)대로 작업이 이루어지지 않았기 때문임.
- 공정 중 저수율 요인을 찾아내면 해당 프로세서의 집중적인 관리를 통해 고수율 웨이퍼의 생산효율을 극대화 할 수 있음. 
- 최적의 Etching 공정 레시피를 제공하고자 함



### 3) 평가지표

#### 재현율



> 양품이라고 판정했지만 실제 불량이 발생한 경우를 예방해야 하므로 **재현율(recall)**이 적절한 평가지표





[평가지표에 대한 개념 정리 블로그에 올리기](http://)



### 4) 프로젝트 기간 

2021/7/26 ~ 2021/8/26



### 5) 프로젝트 분석 환경 도구

- **Language** : python 3.7 ver
- **Hardware / Server** : ubuntu / windows
- **IDE** : Colab, Jupyter lab
- **Tools** : github, Google Drive
- **Analysis Library** : matplotlib, pandas, NumPy, scikit learn, seaborn



## 2.데이터 탐색

- **초기 데이터 shape** : 8145 x 841 
- **데이터의 정보** :  2016/ 1/ 1 부터  2016/ 12/ 31 까지 매 시간마다 측정된 불량 탐지 센서의 데이터. 
  컬럼명을 통해 생산라인이 왼쪽과 오른쪽으로 나누어져 있다는 것을 알 수 있음.
- **1번째 컬럼**은 `YYYY-mm-dd hh`형태의 날짜 시간정보이므로 인덱스로 지정하였음
- **레이블**은 L.RD , L.Vac, R.RD , R.Vac으로 왼쪽과 오른쪽 생산 라인의 RollDown, Vaccum공정의 폐기율을 의미함



## 3.데이터 변환

---

- [1) 결측치 처리](#1-결측치-처리)
- [2) 분산을 이용한 피처 제거](#2-분산을-이용한-피처-제거)
- [3) 피처 분류를 통한 피처 제거](#3-피처-분류를-통한-피처-제거)
- [4) 상관계수를 이용한 피처 제거](#4-상관계수를-이용한-피처-제거)
- [5) VIF를 이용한 피처 제거](#5-vif를-이용한-피처-제거---최종-모델링에서-생략)
- [6) PCA분석](#6-pca분석을-통해-누적-기여율과-elbow-point확인)



### 1) 결측치 처리

- 모든 행이 결측치인 피처 7개 제거
- 나머지 결측치가 3개의 행에 존재 => 시계열 데이터이므로 ffill로 결측치를 채움



### 2) 분산을 이용한 피처 제거

- 분산을 출력하여 분산 값이 0에 수렴하는 피처 7개 제거
  특정 컬럼의 분산이 0이라는 것은 해당 컬럼의 데이터가 거의 변하지 않는다는 의미이므로 불량률에 영향을 주고 있다고 보기 어려움



### 3) 피처 분류를 통한 피처 제거

[해당 처리 소스코드]()

- 피처명에 L, R이 반복 등장함 -> L-왼쪽 생산라인, R-오른쪽 생산라인일 것이라 추측 -> 동일한 공정을 수행하는 별개의 라인이라면 두 라인의 데이터를 모두 사용하는 것은 동일한 데이터가 최종 분류 모델에 중복하여 영향력을 주게 됨
- Left, Right 컬럼별로 분류하여 상관관계 히트맵을 그려본 결과, 두 라인에서 피처간 관계는 비슷한 것을 알 수 있음

<div style="text-align:center"><img src="./docs/images/Left_Columns_Heatmap.png" alt="Left_Columns_Heatmap" style="zoom:30%;" /><img src="./docs/images/Right_Columns_Heatmap.png" alt="Right_Columns_Heatmap" style="zoom: 30%;" />
</div>



- 두 생산 라인 중 하나만 선택하여 피처의 영향력을 조사하도록 함
  - 그 중 피처 수가 더 적은 Right 라인의 피처를 제외하였음



### 4) 상관계수를 이용한 피처 제거

- 상관계수가 0.9이상인 피처를 401개 제거
- 두 피처 간의 상관관계가 높다는 것은, 하나의 피처 값이 다른 피처의 값에 큰 영향을 주고있음을 의미함
- 모델링에 영향을 미치는 원인들이 모두 비슷한 중요도로 반영되게 하려면 종속성이 낮은 피처들만을 이용하여 모델을 만드는 것이 타당함



### 5) VIF를 이용한 피처 제거 - 최종 모델링에서 생략

[VIF와 다중공선성에 대한 개념 정리](https://2sehi.github.io/machine%20learning/15_MachineLearning/)

- VIF계수가 30이하가 될 때까지 VIF계수가 높은 피처을 제거하였음
  - 30이라고 정한 이유는 피처의 수가 너무 많아 10은 너무 낮은 것 같아 30으로 지정함. 숫자의 의미는 딱히 없음
- 이 방법으로 피처를 제거하여 XBGoost 분류를 한 결과, 남은 피처가 모델을 충분히 설명하지 못하는 것 같음 
  => 순차적으로 진행되는 작업으로 수행 시간이 오래 걸리는 작업인 것에 비해 중요 피처가 삭제된 것 같아서 생략



### 6) PCA분석을 통해 누적 기여율과 Elbow Point확인

[PCA에 대한 개념 정리 - 추가하기]()

[4) 상관계수를 이용한 피처 제거](#4-상관계수를-이용한-피처-제거)까지의 전처리 수행한 피처를 대상으로 PCA주성분 분석을 진행하여 누적 기여율과 Elbow Point를 확인하였음

- 누적 기여율 : 누적 기여율이 0.9이상이 되는 피처의 개수는 24개로 전체 데이터의 90%설명 가능함
- Elbow Point : 전체 데이터에 대해 가장 잘 설명하는 주성분의 설명 변수는 0.7로 설명변수의 Scree plot을 그려본 결과, 감소폭이 완만해지기 전까지 7개의 주성분으로 전체 데이터를 전반적으로 설명할 수 있음 👉중요한 피처는 7개일 것으로 추축됨.

#### 분류 모델알고리즘의 feature importance를 전체 데이터의 90%설명 가능한 피처의 개수인 24개로 도출해 낼 것임.



### 7) 레이블 분류 기준

> 레이블 분류 기준은 폐기율 레이블의 값이 0.01보다 큰 데이터를 불량품, 0.01이하인 데이터를 양품으로 지정하였음

#### 왜 0.01인가?

불량품 선정 기준을 폐기율 레이블의 상위 5%인 데이터에 대해 불량품으로 지정하여 XGBoost Classiffier 모델을 수행하여 재현율을 확인하였으나, 불균형한 Decision Tree가 그려지고, 불량품에 영향을 줄 수 있다고 판단되는 피처를 찾기 어려웠음

따라서 , 양품과 불량품의 비율이 불균형한 것으로 판단되어 레이블 값이 0.01이상인 데이터를 불량품으로 지정하면 불량에 영향을 주는 피처를 찾을 수 있을 것이라 판단함.



## 4.모델링

---

분류 모델 알고리즘인 SVM, Ensemble의 Random Forest와 XGBoost를 수행하였음

[SVM, Random Forest, XGBoost에 대한 개념 정리 - 추가](http://추가-예정)

### 1) Decision Tree에서 중요 피처를 찾는 기준

- 최상단에서 가장 먼저 노드를 나누는 피처
- 지니계수가 낮고, 샘플 수가 많고, 불량으로 많이 분류한 노드의 피처
- 어떤 노드에서 피처를 기준으로 다음 노드에서 클래스의 개수가 확연히 분류되는 피처



### 2) XGBoost

1. 모델 훈련

2. 하이퍼파라미터 조정
3.  feature_importance로 24개의 피처 확인 
4. 3에서 확인한 24개의 피처로 Dcision Tree모델 훈련 수행
5. 트리구조 탐색하여 5개의 중요피처 선정



### 3) RandomForest

1. 모델 훈련
2. 하이퍼파라미터 조정
3. feature_importance로 24개의 피처 확인
4. 3에서 확인한 24개의 피처로 Decision Tree모델 훈련 수행
5. 트리구조 탐색하여 5개의 중요 피처 선정

## 5.결론



## 
